{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "34789d78e0994722b661a8fd3cc22715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a408efdacbf4187be78575d80bef373",
              "IPY_MODEL_1b379115bae544c492a9ab3851a34d1a",
              "IPY_MODEL_85367ae859d646fab47140085df9fb5f"
            ],
            "layout": "IPY_MODEL_9a5c20ee966e49eda53672453277dcb1"
          }
        },
        "1a408efdacbf4187be78575d80bef373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c08fd3c21f04aa8a9c5479638a4d676",
            "placeholder": "​",
            "style": "IPY_MODEL_5de8a9a5aa0b4e21bcd6f1de28c935fd",
            "value": "Generating train split: "
          }
        },
        "1b379115bae544c492a9ab3851a34d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_489318b0a76c4017a8d6c88e32a39962",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa3b9f42999d4801a65cde30383c010f",
            "value": 1
          }
        },
        "85367ae859d646fab47140085df9fb5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38d2986ddcf843eca21b27dbb63c10a3",
            "placeholder": "​",
            "style": "IPY_MODEL_36ae48556b4f4e5ea34774fb07a04627",
            "value": " 1/0 [00:00&lt;00:00,  9.38 examples/s]"
          }
        },
        "9a5c20ee966e49eda53672453277dcb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c08fd3c21f04aa8a9c5479638a4d676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de8a9a5aa0b4e21bcd6f1de28c935fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "489318b0a76c4017a8d6c88e32a39962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fa3b9f42999d4801a65cde30383c010f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38d2986ddcf843eca21b27dbb63c10a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36ae48556b4f4e5ea34774fb07a04627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a94867fe8194a769155f6955274a988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c7a9f69d4754b2cb249c78b07c36dea",
              "IPY_MODEL_5a251ddd5a04429691bd67df031dac6c",
              "IPY_MODEL_5853c06e2ddc4e079f6db22beba3960e"
            ],
            "layout": "IPY_MODEL_c0425301c0b8421db7a4d5e0285a1f47"
          }
        },
        "4c7a9f69d4754b2cb249c78b07c36dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd2176388eb643bdbc022999160b626c",
            "placeholder": "​",
            "style": "IPY_MODEL_20de280661d54a109c9a0dcbcff765cb",
            "value": "Generating train split: "
          }
        },
        "5a251ddd5a04429691bd67df031dac6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24eb19864c4c4b92b9b5d98874f1270d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c1dff1839f84e999dfd2a9bbdf0dcd3",
            "value": 1
          }
        },
        "5853c06e2ddc4e079f6db22beba3960e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae14ab21463e4fbe8b099029f3a973c7",
            "placeholder": "​",
            "style": "IPY_MODEL_d9adb86693b74a5bb6155633650b2397",
            "value": " 250/0 [00:00&lt;00:00, 6859.09 examples/s]"
          }
        },
        "c0425301c0b8421db7a4d5e0285a1f47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd2176388eb643bdbc022999160b626c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20de280661d54a109c9a0dcbcff765cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24eb19864c4c4b92b9b5d98874f1270d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7c1dff1839f84e999dfd2a9bbdf0dcd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae14ab21463e4fbe8b099029f3a973c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9adb86693b74a5bb6155633650b2397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fcdd3c9e48d441090c946908a69b5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ad587b367664fcc8c9c37d2af1b3b57",
              "IPY_MODEL_d0bf3c30d47c40359ccde3f98e73744a",
              "IPY_MODEL_1b3f574cd72c426784e4b36560238116"
            ],
            "layout": "IPY_MODEL_0e24f2fb115942ddb809ecbf16f992f5"
          }
        },
        "0ad587b367664fcc8c9c37d2af1b3b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7be2b42e66f341bd95c9407215142ab2",
            "placeholder": "​",
            "style": "IPY_MODEL_41e44909249d4047abf08528070e8a8b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d0bf3c30d47c40359ccde3f98e73744a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9093d8bb1da4405b72c9b49d88362a0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fd2deafdde24b1da80f3b735e9db5cc",
            "value": 2
          }
        },
        "1b3f574cd72c426784e4b36560238116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f9475d11eda429da72c58f20de3c2c2",
            "placeholder": "​",
            "style": "IPY_MODEL_0a99f2c8d7fa473a93c1617d040a4807",
            "value": " 2/2 [00:01&lt;00:00,  1.06it/s]"
          }
        },
        "0e24f2fb115942ddb809ecbf16f992f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7be2b42e66f341bd95c9407215142ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41e44909249d4047abf08528070e8a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9093d8bb1da4405b72c9b49d88362a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fd2deafdde24b1da80f3b735e9db5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f9475d11eda429da72c58f20de3c2c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a99f2c8d7fa473a93c1617d040a4807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94610c6ab88044fd9949c355f39f420a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c29502b33b104a97b0809e9dab4d0553",
              "IPY_MODEL_58e8b6bf68054d65b937a2edd21dc717",
              "IPY_MODEL_191b88da2f5c4be5b0767115fc680c86"
            ],
            "layout": "IPY_MODEL_2cc121778efc497abbf6305c2e6830d3"
          }
        },
        "c29502b33b104a97b0809e9dab4d0553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95b6ba81546948a490fc15bb0ada88e8",
            "placeholder": "​",
            "style": "IPY_MODEL_f9582b32c6cb44dc9842b434a60239e0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "58e8b6bf68054d65b937a2edd21dc717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e817e6a52a4e41b8ad024d5f307d170d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f0ea2c6191b44a69435f806e39bf9a0",
            "value": 2
          }
        },
        "191b88da2f5c4be5b0767115fc680c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6df02b7b457048eeb9ee996802d3b6f7",
            "placeholder": "​",
            "style": "IPY_MODEL_2d61f4fd416343c2bc2ff7d7a8015d49",
            "value": " 2/2 [00:08&lt;00:00,  3.62s/it]"
          }
        },
        "2cc121778efc497abbf6305c2e6830d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95b6ba81546948a490fc15bb0ada88e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9582b32c6cb44dc9842b434a60239e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e817e6a52a4e41b8ad024d5f307d170d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f0ea2c6191b44a69435f806e39bf9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6df02b7b457048eeb9ee996802d3b6f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d61f4fd416343c2bc2ff7d7a8015d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets rouge_score"
      ],
      "metadata": {
        "id": "OcNzYvH7wv_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c069e2fc-fe0d-44fe-9a25-3d0ed5b5da51"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLzkE2k1rw72",
        "outputId": "7a4f9504-0591-4cd7-8664-770d60c3e559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import torch\n",
        "import random\n",
        "import shutil\n",
        "import argparse\n",
        "import datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from accelerate import Accelerator\n",
        "from collections import defaultdict\n",
        "from statistics import mean, harmonic_mean\n",
        "from rouge_score import rouge_scorer\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## args"
      ],
      "metadata": {
        "id": "DjzkhyVnwgS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/GIL/Unlearning/data/validation/'\n",
        "checkpoint_path = '/content/drive/MyDrive/GIL/Unlearning/fine_tune_retain'\n",
        "mia_data_path = '/content/drive/MyDrive/GIL/Unlearning/mia_data/'\n",
        "output_dir = '/content/drive/MyDrive/GIL/Unlearning/'\n",
        "model = '/content/drive/MyDrive/GIL/Unlearning/fine_tune_retain' #allenai/OLMo-1B-0724-hf'\n",
        "max_new_tokens = 256\n",
        "ntrain = 5\n",
        "data_dir = 'cais/mmlu'#https://huggingface.co/datasets/cais/mmlu\n",
        "save_dir = '/content/drive/MyDrive/GIL/Unlearning/results_mmlu/'\n",
        "n_instances = 5\n",
        "eval_batch_size = 1\n",
        "hf_revision = None\n",
        "load_in_8bit = False #Porque lo tenemos en 4\n",
        "\n",
        "debug = False\n",
        "keep_files = False\n",
        "compute_metrics_only = False"
      ],
      "metadata": {
        "id": "4Im0rkQRsUN0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "09vz4DqvvnO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference( model, tokenizer):\n",
        "    forget_file = data_path + 'forget.jsonl'\n",
        "    retain_file = data_path + 'retain.jsonl'\n",
        "\n",
        "    accelerator = Accelerator()\n",
        "    model.to(accelerator.device)\n",
        "\n",
        "    for split, train_file in tqdm([('retain', retain_file), ('forget', forget_file)]):\n",
        "        print('\\nlen retain_file', len(retain_file))\n",
        "        print('len forget_file', len(forget_file))\n",
        "        data_files = {}\n",
        "        dataset_args = {}\n",
        "        if train_file is not None:\n",
        "            data_files[\"train\"] = train_file\n",
        "        raw_datasets = datasets.load_dataset(\n",
        "            \"json\",\n",
        "            data_files=data_files,\n",
        "            **dataset_args,\n",
        "        )\n",
        "        train_dataset = raw_datasets[\"train\"]\n",
        "\n",
        "        output_dic = defaultdict(lambda :{'id': [], 'task': [], 'input': [], 'expected_output': [], 'model_output': [], 'nll': []})\n",
        "\n",
        "        with accelerator.split_between_processes(train_dataset, apply_padding=True) as data:\n",
        "          #Agregué esto, no se si sea lo correcto\n",
        "          print('len data[input]',len(data[\"input\"]))\n",
        "          for i in range(len(data[\"input\"])):\n",
        "              questions, answers = list(data[\"input\"][0].values()), list(data[\"output\"][0].values())\n",
        "              id = list(data[\"id\"][0].values())\n",
        "              task = list(data[\"task\"][0].values())\n",
        "              for idx in range(len(questions)):\n",
        "         #----------\n",
        "                  #question, answer = data[idx][\"input\"], data[idx][\"output\"]\n",
        "                  question, answer = str(questions[idx]), str(answers[idx])\n",
        "                  #print(question, type(question), type(answer))\n",
        "                  output_dic[accelerator.process_index]['id'].append(id[idx])\n",
        "                  output_dic[accelerator.process_index]['task'].append(task[idx])\n",
        "                  output_dic[accelerator.process_index]['input'].append(questions[idx])\n",
        "                  output_dic[accelerator.process_index]['expected_output'].append(answer)\n",
        "                  input_ids = tokenizer(\n",
        "                      question,\n",
        "                      return_tensors='pt',\n",
        "                      padding=True\n",
        "                  ).input_ids.to(model.device)\n",
        "\n",
        "                  combined_input_ids = tokenizer(\n",
        "                      question+answer,\n",
        "                      return_tensors='pt',\n",
        "                  ).input_ids.to(model.device)\n",
        "                  combined_target_ids = combined_input_ids.clone()\n",
        "                  combined_target_ids[:,:len(input_ids[0])] = -100\n",
        "\n",
        "                  with torch.no_grad():\n",
        "                      out = model.generate(input_ids, max_new_tokens=max_new_tokens, do_sample=False, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "                      output_ids = out[:, len(input_ids[0]):]\n",
        "                      output = tokenizer.batch_decode(\n",
        "                          output_ids,\n",
        "                          skip_special_tokens=True,\n",
        "                          clean_up_tokenization_spaces=True)[0]\n",
        "                      output_dic[accelerator.process_index]['model_output'].append(output)\n",
        "\n",
        "                      # For Perplexity\n",
        "                      out = model(combined_input_ids, labels=combined_target_ids)\n",
        "                      if debug:\n",
        "                          print(tokenizer.batch_decode(\n",
        "                              torch.argmax(\n",
        "                                  torch.nn.functional.softmax(\n",
        "                                      torch.tensor(out.logits),\n",
        "                                      dim=2),\n",
        "                                  dim=2)[:, len(input_ids[0]):],\n",
        "                              skip_special_tokens=True,\n",
        "                              clean_up_tokenization_spaces=True)[0])\n",
        "                      neg_log_likelihood = out.loss.item()\n",
        "                      output_dic[accelerator.process_index]['nll'].append(neg_log_likelihood)\n",
        "\n",
        "        accelerator.wait_for_everyone()\n",
        "\n",
        "        #if args.debug:\n",
        "        #    print([len(value) for value in output_dic[accelerator.process_index].values()])\n",
        "        output_df = pd.DataFrame.from_dict(output_dic[accelerator.process_index])\n",
        "        output_file_name = f\"{output_dir}/{split}_{accelerator.process_index}.csv\"\n",
        "        output_df.to_csv(output_file_name, index=False)"
      ],
      "metadata": {
        "id": "RYrCDru7s_x2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mia_attacks(model, tokenizer):\n",
        "    member_file = mia_data_path + 'member.jsonl'\n",
        "    nonmember_file = mia_data_path + 'nonmember.jsonl'\n",
        "\n",
        "    accelerator = Accelerator()\n",
        "    model.to(accelerator.device)\n",
        "\n",
        "    for dataset, train_file in [('member', member_file), ('nonmember', nonmember_file)]:\n",
        "        data_files = {}\n",
        "        dataset_args = {}\n",
        "        if train_file is not None:\n",
        "            data_files[\"train\"] = train_file\n",
        "        raw_datasets = datasets.load_dataset(\n",
        "            \"json\",\n",
        "            data_files=data_files,\n",
        "            **dataset_args,\n",
        "        )\n",
        "        train_dataset = raw_datasets[\"train\"]\n",
        "\n",
        "        output_dic = defaultdict(lambda :{'id': [], 'nll': []})\n",
        "\n",
        "        with accelerator.split_between_processes(train_dataset, apply_padding=True) as data:\n",
        "            for idx in tqdm(range(len(data['document']))):\n",
        "                document = data[\"document\"][idx]\n",
        "                output_dic[accelerator.process_index]['id'].append(data[\"id\"][idx])\n",
        "                input_ids = tokenizer(\n",
        "                    document,\n",
        "                    return_tensors='pt'\n",
        "                ).input_ids.to(model.device)\n",
        "\n",
        "                target_ids = input_ids.clone()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    out = model(input_ids, labels=target_ids)\n",
        "                    neg_log_likelihood = out.loss.item()\n",
        "                    output_dic[accelerator.process_index]['nll'].append(neg_log_likelihood)\n",
        "\n",
        "        accelerator.wait_for_everyone()\n",
        "\n",
        "        output_df = pd.DataFrame.from_dict(output_dic[accelerator.process_index])\n",
        "\n",
        "        #results_dir = os.path.join(args.output_dir, 'mia_results')\n",
        "        #Path(results_dir).mkdir(parents=True, exist_ok=True)\n",
        "        output_file_name = f\"{output_dir}/mia_results/{dataset}_{accelerator.process_index}.csv\"\n",
        "        #if args.debug:\n",
        "        #    print('Saving to: ', output_file_name)\n",
        "        output_df.to_csv(output_file_name, index=False)"
      ],
      "metadata": {
        "id": "Xu8-5YQ8tfzk"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_auc(member_loss, nonmember_loss):\n",
        "    assert not np.any(np.isnan(member_loss))\n",
        "    assert not np.any(np.isnan(nonmember_loss))\n",
        "    combined_loss = member_loss + nonmember_loss\n",
        "    combined_loss = -1 * np.array(combined_loss)\n",
        "    combined_labels = len(member_loss) * [1] + len(nonmember_loss) * [0]\n",
        "    fp, tp, _ = roc_curve(combined_labels, combined_loss)\n",
        "\n",
        "    auc_score = float(auc(fp, tp))\n",
        "\n",
        "    return auc_score"
      ],
      "metadata": {
        "id": "f7bC0fYauWxz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics():\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    results = {}\n",
        "    aggregate_scores_list = []\n",
        "    for split in ['forget', 'retain']:\n",
        "        #files = glob.glob(output_dir + '/{}_*.csv'.format(split))\n",
        "        #if len(files) == 0:\n",
        "        #    print(\"[ERROR] Missing inference files, rerun script with inference first\")\n",
        "        #    return  # sys.exit(1) throws a long traceback so just return for now\n",
        "        files = [f'{output_dir}/forget_0.csv', f'{output_dir}/retain_0.csv']\n",
        "        df_list = [pd.read_csv(f) for f in files]\n",
        "        #if not args.keep_files:\n",
        "        #    _ = [os.remove(f) for f in files]\n",
        "        df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "        df['regurgitation-score-rouge-1'] = None\n",
        "        df['regurgitation-score'] = None\n",
        "        df['knowledge-score'] = None\n",
        "        ground_truths = df['expected_output'].tolist()\n",
        "        gen_outputs = df['model_output'].tolist()\n",
        "\n",
        "        for i, (gen, gt) in enumerate(zip(gen_outputs, ground_truths)):\n",
        "            if df.loc[i, 'id'][:-1].endswith('sc'):\n",
        "                rouge_scores = scorer.score(str(gt), str(gen))\n",
        "                df.loc[i, 'regurgitation-score-rouge-1'] = rouge_scores['rouge1'].recall\n",
        "                df.loc[i, 'regurgitation-score'] = rouge_scores['rougeL'].recall\n",
        "            elif df.loc[i, 'id'][:-1].endswith('qa'):\n",
        "                 df.loc[i, 'knowledge-score'] = int(str(gt).strip().lower() == str(gen).strip().lower())\n",
        "\n",
        "        results[split+'-set'] = {'overall-regurgitation-score': np.mean(df['regurgitation-score']), 'overall-knowledge-score': np.mean(df['knowledge-score'])}\n",
        "        split_aggregate_scores_dict = df.groupby('task')[['regurgitation-score', 'knowledge-score']].mean().to_dict(orient='index')\n",
        "        results[split+'-set'].update(split_aggregate_scores_dict)\n",
        "        split_aggregate_score_values = [float(val) for inner in split_aggregate_scores_dict.values() for val in inner.values()]\n",
        "        if split == 'forget':\n",
        "            split_aggregate_score_values = [(1 - val) for val in split_aggregate_score_values]\n",
        "\n",
        "        aggregate_scores_list.extend(split_aggregate_score_values)\n",
        "\n",
        "    if mia_data_path is not None:\n",
        "        mia_results_dir = output_dir+'mia_results'\n",
        "        mia_results = {}\n",
        "        for dataset in ['member', 'nonmember']:\n",
        "            #files = glob.glob(mia_results_dir + '/{}_*.csv'.format(dataset))\n",
        "            #if len(files) == 0:\n",
        "            #    print(\"[ERROR] Missing mia files, rerun script with inference first\")\n",
        "            #    return  # sys.exit(1) throws a long traceback so just return for no\n",
        "            files = [f'{mia_results_dir}/member_0.csv', f'{mia_results_dir}/nonmember_0.csv']\n",
        "            df_list = [pd.read_csv(f) for f in files]\n",
        "            df = pd.concat(df_list, ignore_index=True)\n",
        "            mia_results[dataset] = df['nll'].tolist()\n",
        "\n",
        "        #if not keep_files:\n",
        "        #    shutil.rmtree(mia_results_dir)\n",
        "\n",
        "        auc = compute_auc(mia_results['member'], mia_results['nonmember'])\n",
        "        # Best MIA rates we can get are ~0.5.\n",
        "        # Scores close to 1 suggest under-unlearning\n",
        "        # Scores close to 0 suggest over-unlearning\n",
        "        results['mia_loss_acc'] = auc\n",
        "#        aggregate_scores_list.append(1 - auc)\n",
        "\n",
        "    if mmlu_metrics_file_path is not None:\n",
        "        with open(mmlu_metrics_file_path) as inptr:\n",
        "            mmlu_scores = json.loads(inptr.read())\n",
        "        results['mmlu_average'] = mmlu_scores['average_acc']\n",
        "#        aggregate_scores_list.append(mmlu_scores['average_acc'])\n",
        "\n",
        "    results['aggregated-terms'] = aggregate_scores_list\n",
        "\n",
        "    task_aggregate = harmonic_mean(aggregate_scores_list)\n",
        "    results['aggregate-score'] = -1\n",
        "\n",
        "    results['harmonic-mean-task-aggregate'] = task_aggregate\n",
        "\n",
        "    # Need MMLU and MIA scores to compute the aggregate\n",
        "    if 'mmlu_average' in results and 'mia_loss_acc' in results:\n",
        "        if results['mmlu_average'] < 0.371:\n",
        "            # MMLU score should not drop below 75% of pre-unlearning preformance\n",
        "            print(f\"[WARNING] The MMLU average for the provided checkpoint is below threshold. If this happens your model may not be considered in final challenge ranking.\")\n",
        "\n",
        "        mia_final_score = 1 - abs(results['mia_loss_acc'] - 0.5)*2\n",
        "        results['mia_final_score'] = mia_final_score\n",
        "        results['aggregate-score'] = mean([task_aggregate, results['mmlu_average'], mia_final_score])\n",
        "\n",
        "    #metrics_file = os.path.join(args.output_dir, 'evaluation_results.jsonl')\n",
        "    #with open(metrics_file, 'w') as outptr:\n",
        "    #    outptr.write(json.dumps(results))\n",
        "    return results"
      ],
      "metadata": {
        "id": "TJsWkl51ubRj"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions MMLU"
      ],
      "metadata": {
        "id": "JqdFA10O2whX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subcategories = {\n",
        "    \"abstract_algebra\": [\"math\"],\n",
        "    \"anatomy\": [\"health\"],\n",
        "    \"astronomy\": [\"physics\"],\n",
        "    \"business_ethics\": [\"business\"],\n",
        "    \"clinical_knowledge\": [\"health\"],\n",
        "    \"college_biology\": [\"biology\"],\n",
        "    \"college_chemistry\": [\"chemistry\"],\n",
        "    \"college_computer_science\": [\"computer science\"],\n",
        "    \"college_mathematics\": [\"math\"],\n",
        "    \"college_medicine\": [\"health\"],\n",
        "    \"college_physics\": [\"physics\"],\n",
        "    \"computer_security\": [\"computer science\"],\n",
        "    \"conceptual_physics\": [\"physics\"],\n",
        "    \"econometrics\": [\"economics\"],\n",
        "    \"electrical_engineering\": [\"engineering\"],\n",
        "    \"elementary_mathematics\": [\"math\"],\n",
        "    \"formal_logic\": [\"philosophy\"],\n",
        "    \"global_facts\": [\"other\"],\n",
        "    \"high_school_biology\": [\"biology\"],\n",
        "    \"high_school_chemistry\": [\"chemistry\"],\n",
        "    \"high_school_computer_science\": [\"computer science\"],\n",
        "    \"high_school_european_history\": [\"history\"],\n",
        "    \"high_school_geography\": [\"geography\"],\n",
        "    \"high_school_government_and_politics\": [\"politics\"],\n",
        "    \"high_school_macroeconomics\": [\"economics\"],\n",
        "    \"high_school_mathematics\": [\"math\"],\n",
        "    \"high_school_microeconomics\": [\"economics\"],\n",
        "    \"high_school_physics\": [\"physics\"],\n",
        "    \"high_school_psychology\": [\"psychology\"],\n",
        "    \"high_school_statistics\": [\"math\"],\n",
        "    \"high_school_us_history\": [\"history\"],\n",
        "    \"high_school_world_history\": [\"history\"],\n",
        "    \"human_aging\": [\"health\"],\n",
        "    \"human_sexuality\": [\"culture\"],\n",
        "    \"international_law\": [\"law\"],\n",
        "    \"jurisprudence\": [\"law\"],\n",
        "    \"logical_fallacies\": [\"philosophy\"],\n",
        "    \"machine_learning\": [\"computer science\"],\n",
        "    \"management\": [\"business\"],\n",
        "    \"marketing\": [\"business\"],\n",
        "    \"medical_genetics\": [\"health\"],\n",
        "    \"miscellaneous\": [\"other\"],\n",
        "    \"moral_disputes\": [\"philosophy\"],\n",
        "    \"moral_scenarios\": [\"philosophy\"],\n",
        "    \"nutrition\": [\"health\"],\n",
        "    \"philosophy\": [\"philosophy\"],\n",
        "    \"prehistory\": [\"history\"],\n",
        "    \"professional_accounting\": [\"other\"],\n",
        "    \"professional_law\": [\"law\"],\n",
        "    \"professional_medicine\": [\"health\"],\n",
        "    \"professional_psychology\": [\"psychology\"],\n",
        "    \"public_relations\": [\"politics\"],\n",
        "    \"security_studies\": [\"politics\"],\n",
        "    \"sociology\": [\"culture\"],\n",
        "    \"us_foreign_policy\": [\"politics\"],\n",
        "    \"virology\": [\"health\"],\n",
        "    \"world_religions\": [\"philosophy\"],\n",
        "}\n",
        "\n",
        "categories = {\n",
        "    \"STEM\": [\"physics\", \"chemistry\", \"biology\", \"computer science\", \"math\", \"engineering\"],\n",
        "    \"humanities\": [\"history\", \"philosophy\", \"law\"],\n",
        "    \"social sciences\": [\"politics\", \"culture\", \"economics\", \"geography\", \"psychology\"],\n",
        "    \"other (business, health, misc.)\": [\"other\", \"business\", \"health\"],\n",
        "}"
      ],
      "metadata": {
        "id": "KHUK8t5e4cM-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "choices = [\"A\", \"B\", \"C\", \"D\"]\n",
        "\n",
        "\n",
        "def format_subject(subject):\n",
        "    l = subject.split(\"_\")\n",
        "    s = \"\"\n",
        "    for entry in l:\n",
        "        s += \" \" + entry\n",
        "    return s\n",
        "\n",
        "\n",
        "def format_example(df, idx, include_answer=True):\n",
        "    prompt = df.iloc[idx, 0]\n",
        "    k = df.shape[1] - 2\n",
        "    for j in range(k):\n",
        "        prompt += \"\\n{}. {}\".format(choices[j], df.iloc[idx, j + 1])\n",
        "    prompt += \"\\nAnswer:\"\n",
        "    if include_answer:\n",
        "        prompt += \" {}\\n\\n\".format(df.iloc[idx, k + 1])\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def gen_prompt(train_df, subject, k=-1):\n",
        "    prompt = \"The following are multiple choice questions (with answers) about {}.\\n\\n\".format(\n",
        "        format_subject(subject)\n",
        "    )\n",
        "    if k == -1:\n",
        "        k = train_df.shape[0]\n",
        "    for i in range(k):\n",
        "        prompt += format_example(train_df, i)\n",
        "    return prompt\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_next_word_predictions(model, tokenizer, prompts, candidate_token_ids=None, batch_size=1, return_token_predictions=False, add_special_tokens=True, disable_tqdm=False):\n",
        "    predictions, probs = [], []\n",
        "    if not disable_tqdm:\n",
        "        progress = tqdm(total=len(prompts), desc=\"Getting Predictions\")\n",
        "\n",
        "    for i in range(0, len(prompts), batch_size):\n",
        "        batch_prompts = prompts[i: i+batch_size]\n",
        "        tokenized_prompts = tokenizer(batch_prompts, padding=\"longest\", return_tensors=\"pt\", add_special_tokens=add_special_tokens)\n",
        "        batch_input_ids = tokenized_prompts.input_ids\n",
        "        attention_mask = tokenized_prompts.attention_mask\n",
        "\n",
        "        if model.device.type == \"cuda\":\n",
        "            batch_input_ids = batch_input_ids.cuda()\n",
        "            attention_mask = attention_mask.cuda()\n",
        "\n",
        "        batch_logits = model(input_ids=batch_input_ids, attention_mask=attention_mask).logits[:, -1, :]\n",
        "        batch_probs = torch.softmax(batch_logits, dim=-1)\n",
        "        if candidate_token_ids is not None:\n",
        "            batch_probs = batch_probs[:, candidate_token_ids]\n",
        "        batch_prediction_indices = torch.argmax(batch_probs, dim=-1)\n",
        "        if return_token_predictions:\n",
        "            if candidate_token_ids is not None:\n",
        "                candidate_tokens = tokenizer.convert_ids_to_tokens(candidate_token_ids)\n",
        "                batch_predictions = [candidate_tokens[idx] for idx in batch_prediction_indices]\n",
        "            else:\n",
        "                batch_predictions = tokenizer.convert_ids_to_tokens(batch_prediction_indices)\n",
        "            predictions += batch_predictions\n",
        "        else:\n",
        "            predictions += batch_prediction_indices.tolist()\n",
        "        probs += batch_probs.tolist()\n",
        "\n",
        "        if not disable_tqdm:\n",
        "            progress.update(len(batch_prompts))\n",
        "\n",
        "    assert len(predictions) == len(prompts), \"number of predictions should be equal to number of prompts\"\n",
        "    return predictions, probs\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_hf_model(subject, model, tokenizer, dev_df, test_df, batch_size=1):\n",
        "    prompts = []\n",
        "    for i in range(0, test_df.shape[0]):\n",
        "        k = ntrain\n",
        "        prompt_end = format_example(test_df, i, include_answer=False)\n",
        "        train_prompt = gen_prompt(dev_df, subject, k)\n",
        "        prompt = train_prompt + prompt_end\n",
        "        tokenized_prompt = tokenizer(prompt, truncation=False, add_special_tokens=False).input_ids\n",
        "        # make sure every prompt is less than 2048 tokens\n",
        "        while len(tokenized_prompt) > 2048:\n",
        "            k -= 1\n",
        "            train_prompt = gen_prompt(dev_df, subject, k)\n",
        "            prompt = train_prompt + prompt_end\n",
        "            tokenized_prompt = tokenizer(prompt, truncation=False, add_special_tokens=False).input_ids\n",
        "        prompts.append(prompt)\n",
        "\n",
        "    # get the answer for all examples\n",
        "    # adding a prefix space here, as that's expected from the prompt\n",
        "    # TODO: should raise a warning if this returns more than one token\n",
        "    answer_choice_ids = [tokenizer.encode(\" \" + answer_choice, add_special_tokens=False)[-1] for answer_choice in choices]\n",
        "    pred_indices, all_probs = get_next_word_predictions(\n",
        "        model, tokenizer, prompts, candidate_token_ids=answer_choice_ids, return_token_predictions=False, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # get the metrics\n",
        "    cors = []\n",
        "    groud_truths = test_df.iloc[:, -1].values\n",
        "    for i in range(len(pred_indices)):\n",
        "        prediction = choices[pred_indices[i]]\n",
        "        ground_truth = groud_truths[i]\n",
        "        cors.append(prediction == ground_truth)\n",
        "\n",
        "    acc = np.mean(cors)\n",
        "    cors = np.array(cors)\n",
        "\n",
        "    all_probs = np.array(all_probs)\n",
        "    print(\"Average accuracy {:.3f} - {}\".format(acc, subject))\n",
        "    return cors, acc, all_probs"
      ],
      "metadata": {
        "id": "mxab2VoP2z0r"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_hf_tokenizer(\n",
        "        model_name_or_path,\n",
        "        revision=None,\n",
        "        tokenizer_name_or_path=None,\n",
        "        use_fast_tokenizer=True,\n",
        "        padding_side=\"left\",\n",
        "        token=os.getenv(\"HF_TOKEN\", None),\n",
        "    ):\n",
        "        from transformers import AutoTokenizer\n",
        "        if not tokenizer_name_or_path:\n",
        "            tokenizer_name_or_path = model_name_or_path\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path, use_fast=use_fast_tokenizer, token=token, revision=revision)\n",
        "        except:\n",
        "            # some tokenizers (e.g., GPTNeoXTokenizer) don't have the slow or fast version, so we just roll back to the default one\n",
        "            tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path, token=token, revision=revision)\n",
        "        # set padding side to left for batch generation\n",
        "        tokenizer.padding_side = padding_side\n",
        "        # set pad token to eos token if pad token is not set (as is the case for llama models)\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "            tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "        return tokenizer"
      ],
      "metadata": {
        "id": "klb-Sr6NY4jC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_hf_lm(\n",
        "        model_name_or_path,\n",
        "        revision=None,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=\"auto\",\n",
        "        load_in_8bit=False,\n",
        "        convert_to_half=False,\n",
        "        gptq_model=False,\n",
        "        token=os.getenv(\"HF_TOKEN\", None),\n",
        "    ):\n",
        "\n",
        "    # Loading OLMo models from HF requires `trust_remote_code=True`.\n",
        "    # TODO: Implement this via command-line flag rather than hardcoded list.\n",
        "    trusted_models = [\"allenai/OLMo-7B\", \"allenai/OLMo-7B-Twin-2T\", \"allenai/OLMo-1B\"]\n",
        "    if model_name_or_path in trusted_models:\n",
        "        trust_remote_code = True\n",
        "    else:\n",
        "        trust_remote_code = False\n",
        "\n",
        "    from transformers import AutoModelForCausalLM, AutoTokenizer, OPTForCausalLM, GPTNeoXForCausalLM\n",
        "    if gptq_model:\n",
        "        from auto_gptq import AutoGPTQForCausalLM\n",
        "        model_wrapper = AutoGPTQForCausalLM.from_quantized(\n",
        "            model_name_or_path, device=\"cuda:0\", use_triton=True, trust_remote_code=trust_remote_code\n",
        "        )\n",
        "        model = model_wrapper.model\n",
        "    elif load_in_8bit:\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name_or_path,\n",
        "            revision=revision,\n",
        "            device_map=device_map,\n",
        "            load_in_8bit=True,\n",
        "            token=token,\n",
        "            trust_remote_code=trust_remote_code\n",
        "        )\n",
        "    else:\n",
        "        if device_map:\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_name_or_path,\n",
        "                revision=revision,\n",
        "                device_map=device_map,\n",
        "                torch_dtype=torch_dtype,\n",
        "                token=token,\n",
        "                trust_remote_code=trust_remote_code,\n",
        "            )\n",
        "        else:\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_name_or_path,\n",
        "                revision=revision,\n",
        "                torch_dtype=torch_dtype,\n",
        "                token=token,\n",
        "                trust_remote_code=trust_remote_code,\n",
        "            )\n",
        "            if torch.cuda.is_available():\n",
        "                model = model.cuda()\n",
        "        if convert_to_half:\n",
        "            model = model.half()\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "qBwtiOrAY6JF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_MMLU(model_path):\n",
        "    if model_path:\n",
        "        print(\"Loading model and tokenizer...\")\n",
        "        tokenizer = load_hf_tokenizer(\n",
        "            model_name_or_path=model_path,\n",
        "            revision=hf_revision,\n",
        "            tokenizer_name_or_path=model_path,\n",
        "            #use_fast_tokenizer=not args.use_slow_tokenizer,\n",
        "        )\n",
        "        model = load_hf_lm(\n",
        "            model_name_or_path=model_path,\n",
        "            revision=hf_revision,\n",
        "            load_in_8bit=load_in_8bit,\n",
        "            device_map=\"balanced_low_0\" if torch.cuda.device_count() > 1 else \"auto\",\n",
        "            #gptq_model=gptq,\n",
        "        )\n",
        "        from transformers import GPTNeoXForCausalLM, OPTForCausalLM\n",
        "        if isinstance(model, GPTNeoXForCausalLM) or isinstance(model, OPTForCausalLM):\n",
        "            tokenizer.model_max_length = model.config.max_position_embeddings\n",
        "            print(\"Set tokenizer.model_max_length to model.config.max_position_embeddings: {}\".format(model.config.max_position_embeddings))\n",
        "\n",
        "    all_cors = []\n",
        "    subcat_cors = {\n",
        "        subcat: [] for subcat_lists in subcategories.values() for subcat in subcat_lists\n",
        "    }\n",
        "    cat_cors = {cat: [] for cat in categories}\n",
        "    #cambiarle a list(subcategories.keys())\n",
        "    for subject in tqdm(list(subcategories.keys())[:2], desc=f\"Evaluating subjects: \"):\n",
        "        dev_df = load_dataset(data_dir, subject, split=\"dev\").to_pandas()\n",
        "        #dev_df = dev_df[dev_df[\"subject\"] == subject][: ntrain]\n",
        "        test_df = load_dataset(data_dir, subject, split=\"test\").to_pandas()\n",
        "        #test_df = test_df[test_df[\"subject\"] == subject]\n",
        "\n",
        "        '''dev_df = pd.read_csv(\n",
        "            os.path.join(args.data_dir, \"dev\", subject + \"_dev.csv\"), header=None\n",
        "        )[: ntrain]\n",
        "        test_df = pd.read_csv(\n",
        "            os.path.join(args.data_dir, \"test\", subject + \"_test.csv\"), header=None\n",
        "        )'''\n",
        "\n",
        "        if n_instances and n_instances < test_df.shape[0]:\n",
        "            test_df = test_df.sample(n_instances, random_state=42)\n",
        "\n",
        "        cors, acc, probs = eval_hf_model(subject, model, tokenizer, dev_df, test_df, eval_batch_size)\n",
        "\n",
        "        subcats = subcategories[subject]\n",
        "        for subcat in subcats:\n",
        "            subcat_cors[subcat].append(cors)\n",
        "            for key in categories.keys():\n",
        "                if subcat in categories[key]:\n",
        "                    cat_cors[key].append(cors)\n",
        "        all_cors.append(cors)\n",
        "\n",
        "        test_df[\"correct\"] = cors\n",
        "        for j in range(probs.shape[1]):\n",
        "            choice = choices[j]\n",
        "            test_df[\"choice{}_probs\".format(choice)] = probs[:, j]\n",
        "        test_df.to_csv(f\"{save_dir}{subject}.csv\",index=None)\n",
        "\n",
        "    for subcat in subcat_cors:\n",
        "        subcat_acc = np.mean(subcat_cors[subcat])\n",
        "        print(\"Average accuracy {:.3f} - {}\".format(subcat_acc, subcat))\n",
        "\n",
        "    for cat in cat_cors:\n",
        "        cat_acc = np.mean(cat_cors[cat])\n",
        "        print(\"Average accuracy {:.3f} - {}\".format(cat_acc, cat))\n",
        "    weighted_acc = np.mean(np.concatenate(all_cors))\n",
        "    print(\"Average accuracy: {:.3f}\".format(weighted_acc))\n",
        "\n",
        "    res = {\n",
        "                \"average_acc\": weighted_acc,\n",
        "                \"subcat_acc\": {\n",
        "                    subcat: np.mean(subcat_cors[subcat])\n",
        "                    for subcat in subcat_cors\n",
        "                },\n",
        "                \"cat_acc\": {\n",
        "                    cat: np.mean(cat_cors[cat])\n",
        "                    for cat in cat_cors\n",
        "                },\n",
        "            }\n",
        "    print(res)\n",
        "\n",
        "    # save results\n",
        "    with open(f\"{save_dir}metrics.json\", \"w\") as f:\n",
        "        json.dump(res,f,)\n"
      ],
      "metadata": {
        "id": "HoJa7SDS3AFj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_MMLU(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834,
          "referenced_widgets": [
            "3fcdd3c9e48d441090c946908a69b5d5",
            "0ad587b367664fcc8c9c37d2af1b3b57",
            "d0bf3c30d47c40359ccde3f98e73744a",
            "1b3f574cd72c426784e4b36560238116",
            "0e24f2fb115942ddb809ecbf16f992f5",
            "7be2b42e66f341bd95c9407215142ab2",
            "41e44909249d4047abf08528070e8a8b",
            "e9093d8bb1da4405b72c9b49d88362a0",
            "3fd2deafdde24b1da80f3b735e9db5cc",
            "2f9475d11eda429da72c58f20de3c2c2",
            "0a99f2c8d7fa473a93c1617d040a4807"
          ]
        },
        "id": "w93Hb4l4ZFoQ",
        "outputId": "1e4bcbc0-a6fb-4ffb-d188-40f9efbb908c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model and tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fcdd3c9e48d441090c946908a69b5d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating subjects:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Getting Predictions:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "Getting Predictions:  20%|██        | 1/5 [00:22<01:30, 22.61s/it]\u001b[A\n",
            "Getting Predictions:  40%|████      | 2/5 [00:42<01:03, 21.09s/it]\u001b[A\n",
            "Getting Predictions:  60%|██████    | 3/5 [01:01<00:39, 19.86s/it]\u001b[A\n",
            "Getting Predictions:  80%|████████  | 4/5 [01:19<00:19, 19.33s/it]\u001b[A\n",
            "Getting Predictions: 100%|██████████| 5/5 [01:41<00:00, 20.22s/it]\n",
            "Evaluating subjects:  50%|█████     | 1/2 [01:45<01:45, 105.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy 0.000 - abstract_algebra\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Getting Predictions:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "Getting Predictions:  20%|██        | 1/5 [00:17<01:09, 17.49s/it]\u001b[A\n",
            "Getting Predictions:  40%|████      | 2/5 [00:36<00:54, 18.25s/it]\u001b[A\n",
            "Getting Predictions:  60%|██████    | 3/5 [00:56<00:38, 19.01s/it]\u001b[A\n",
            "Getting Predictions:  80%|████████  | 4/5 [01:16<00:19, 19.71s/it]\u001b[A\n",
            "Getting Predictions: 100%|██████████| 5/5 [01:35<00:00, 19.10s/it]\n",
            "Evaluating subjects: 100%|██████████| 2/2 [03:24<00:00, 102.07s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy 0.000 - anatomy\n",
            "Average accuracy 0.000 - math\n",
            "Average accuracy 0.000 - health\n",
            "Average accuracy nan - physics\n",
            "Average accuracy nan - business\n",
            "Average accuracy nan - biology\n",
            "Average accuracy nan - chemistry\n",
            "Average accuracy nan - computer science\n",
            "Average accuracy nan - economics\n",
            "Average accuracy nan - engineering\n",
            "Average accuracy nan - philosophy\n",
            "Average accuracy nan - other\n",
            "Average accuracy nan - history\n",
            "Average accuracy nan - geography\n",
            "Average accuracy nan - politics\n",
            "Average accuracy nan - psychology\n",
            "Average accuracy nan - culture\n",
            "Average accuracy nan - law\n",
            "Average accuracy 0.000 - STEM\n",
            "Average accuracy nan - humanities\n",
            "Average accuracy nan - social sciences\n",
            "Average accuracy 0.000 - other (business, health, misc.)\n",
            "Average accuracy: 0.000\n",
            "{'average_acc': 0.0, 'subcat_acc': {'math': 0.0, 'health': 0.0, 'physics': nan, 'business': nan, 'biology': nan, 'chemistry': nan, 'computer science': nan, 'economics': nan, 'engineering': nan, 'philosophy': nan, 'other': nan, 'history': nan, 'geography': nan, 'politics': nan, 'psychology': nan, 'culture': nan, 'law': nan}, 'cat_acc': {'STEM': 0.0, 'humanities': nan, 'social sciences': nan, 'other (business, health, misc.)': 0.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "k24gCQISvZBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Set up accelerator\n",
        "accelerator = Accelerator()\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, torch_dtype=torch.bfloat16, trust_remote_code = True) # .to('cuda')\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "94610c6ab88044fd9949c355f39f420a",
            "c29502b33b104a97b0809e9dab4d0553",
            "58e8b6bf68054d65b937a2edd21dc717",
            "191b88da2f5c4be5b0767115fc680c86",
            "2cc121778efc497abbf6305c2e6830d3",
            "95b6ba81546948a490fc15bb0ada88e8",
            "f9582b32c6cb44dc9842b434a60239e0",
            "e817e6a52a4e41b8ad024d5f307d170d",
            "8f0ea2c6191b44a69435f806e39bf9a0",
            "6df02b7b457048eeb9ee996802d3b6f7",
            "2d61f4fd416343c2bc2ff7d7a8015d49"
          ]
        },
        "id": "cV-Z2QuKcf8v",
        "outputId": "7853cb5d-2da7-40ee-ab5c-0af3908de193"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94610c6ab88044fd9949c355f39f420a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not compute_metrics_only:\n",
        "    inference(model, tokenizer)"
      ],
      "metadata": {
        "id": "tw3c8Gh9cmnD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "34789d78e0994722b661a8fd3cc22715",
            "1a408efdacbf4187be78575d80bef373",
            "1b379115bae544c492a9ab3851a34d1a",
            "85367ae859d646fab47140085df9fb5f",
            "9a5c20ee966e49eda53672453277dcb1",
            "4c08fd3c21f04aa8a9c5479638a4d676",
            "5de8a9a5aa0b4e21bcd6f1de28c935fd",
            "489318b0a76c4017a8d6c88e32a39962",
            "fa3b9f42999d4801a65cde30383c010f",
            "38d2986ddcf843eca21b27dbb63c10a3",
            "36ae48556b4f4e5ea34774fb07a04627"
          ]
        },
        "outputId": "ab3663fc-dee7-4e66-ac76-470ad90c7d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "len retain_file 66\n",
            "len forget_file 66\n",
            "len data[input] 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 1/2 [12:45<12:45, 765.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "len retain_file 66\n",
            "len forget_file 66\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34789d78e0994722b661a8fd3cc22715"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len data[input] 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [26:08<00:00, 784.15s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if mia_data_path is not None:\n",
        "    mia_attacks(model, tokenizer)"
      ],
      "metadata": {
        "id": "MTavhOEZctSr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "1a94867fe8194a769155f6955274a988",
            "4c7a9f69d4754b2cb249c78b07c36dea",
            "5a251ddd5a04429691bd67df031dac6c",
            "5853c06e2ddc4e079f6db22beba3960e",
            "c0425301c0b8421db7a4d5e0285a1f47",
            "fd2176388eb643bdbc022999160b626c",
            "20de280661d54a109c9a0dcbcff765cb",
            "24eb19864c4c4b92b9b5d98874f1270d",
            "7c1dff1839f84e999dfd2a9bbdf0dcd3",
            "ae14ab21463e4fbe8b099029f3a973c7",
            "d9adb86693b74a5bb6155633650b2397"
          ]
        },
        "outputId": "1652d2ec-5cc0-4f48-a3c1-8ad9395012d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 250/250 [01:01<00:00,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a94867fe8194a769155f6955274a988"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 250/250 [01:03<00:00,  3.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mmlu_metrics_file_path = '/content/drive/MyDrive/GIL/Unlearning/results_mmlu/metrics.json'\n"
      ],
      "metadata": {
        "id": "t_zaHhrC2IV1"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if accelerator.is_main_process:\n",
        "    res = compute_metrics()\n",
        "res"
      ],
      "metadata": {
        "id": "9iMeRTXDxfKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb8a64e-3d1b-4e6f-9f65-354283f5eb83"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARNING] The MMLU average for the provided checkpoint is below threshold. If this happens your model may not be considered in final challenge ranking.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'forget-set': {'overall-regurgitation-score': 0.23542884518765667,\n",
              "  'overall-knowledge-score': 0.0,\n",
              "  'Task1': {'regurgitation-score': 0.35715384035868203,\n",
              "   'knowledge-score': 0.0},\n",
              "  'Task2': {'regurgitation-score': 0.13832551140051963,\n",
              "   'knowledge-score': 0.0},\n",
              "  'Task3': {'regurgitation-score': 0.2136399053011814,\n",
              "   'knowledge-score': 0.0}},\n",
              " 'retain-set': {'overall-regurgitation-score': 0.23542884518765667,\n",
              "  'overall-knowledge-score': 0.0,\n",
              "  'Task1': {'regurgitation-score': 0.35715384035868203,\n",
              "   'knowledge-score': 0.0},\n",
              "  'Task2': {'regurgitation-score': 0.13832551140051963,\n",
              "   'knowledge-score': 0.0},\n",
              "  'Task3': {'regurgitation-score': 0.2136399053011814,\n",
              "   'knowledge-score': 0.0}},\n",
              " 'mia_loss_acc': 0.5,\n",
              " 'mmlu_average': 0.0,\n",
              " 'aggregated-terms': [0.642846159641318,\n",
              "  1.0,\n",
              "  0.8616744885994804,\n",
              "  1.0,\n",
              "  0.7863600946988186,\n",
              "  1.0,\n",
              "  0.35715384035868203,\n",
              "  0.0,\n",
              "  0.13832551140051963,\n",
              "  0.0,\n",
              "  0.2136399053011814,\n",
              "  0.0],\n",
              " 'aggregate-score': 0.3333333333333333,\n",
              " 'harmonic-mean-task-aggregate': 0,\n",
              " 'mia_final_score': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdkaInyNY5Xy",
        "outputId": "538cb320-c944-44f8-b27e-059bdb691479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'forget-set': {'overall-regurgitation-score': 0.23542884518765667,\n",
              "  'overall-knowledge-score': 0.0,\n",
              "  'Task1': {'regurgitation-score': 0.35715384035868203,\n",
              "   'knowledge-score': 0.0},\n",
              "  'Task2': {'regurgitation-score': 0.13832551140051963,\n",
              "   'knowledge-score': 0.0},\n",
              "  'Task3': {'regurgitation-score': 0.2136399053011814,\n",
              "   'knowledge-score': 0.0}},\n",
              " 'retain-set': {'overall-regurgitation-score': 0.23542884518765667,\n",
              "  'overall-knowledge-score': 0.0,\n",
              "  'Task1': {'regurgitation-score': 0.35715384035868203,\n",
              "   'knowledge-score': 0.0},\n",
              "  'Task2': {'regurgitation-score': 0.13832551140051963,\n",
              "   'knowledge-score': 0.0},\n",
              "  'Task3': {'regurgitation-score': 0.2136399053011814,\n",
              "   'knowledge-score': 0.0}},\n",
              " 'mia_loss_acc': 0.5,\n",
              " 'aggregated-terms': [0.642846159641318,\n",
              "  1.0,\n",
              "  0.8616744885994804,\n",
              "  1.0,\n",
              "  0.7863600946988186,\n",
              "  1.0,\n",
              "  0.35715384035868203,\n",
              "  0.0,\n",
              "  0.13832551140051963,\n",
              "  0.0,\n",
              "  0.2136399053011814,\n",
              "  0.0],\n",
              " 'harmonic-mean-task-aggregate': 0,\n",
              " 'aggregate-score': -1}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Apxfo5fXaEff"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}