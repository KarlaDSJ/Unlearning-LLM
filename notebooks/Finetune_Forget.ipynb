{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antes de correr el programa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para asegurarse que no haya problemas con las rutas, se debe mover el programa a la carpeta principal o cambiar de manera manual las rutas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direcciones\n",
    "data_root_dir = \"./Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algunas funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_input_output(input, output):\n",
    "  \"\"\"It concatenates the input and the LLM output\"\"\"\n",
    "  text = []\n",
    "  for i,o in zip(input, output):\n",
    "    text.append(f'{i}\\n  {o}')\n",
    "  return text\n",
    "\n",
    "def analisis_modelo(model):\n",
    "    print(model)\n",
    "    for param_tensor in model.state_dict():\n",
    "        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraccion del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          id  \\\n",
      "0  \"2ebbbb06-ab81-4bdf-af75-0157c7178a82\"sc1   \n",
      "1  \"2ebbbb06-ab81-4bdf-af75-0157c7178a82\"qa0   \n",
      "2                                67148749sc1   \n",
      "3                                67148749qa0   \n",
      "4  \"4477840f-1840-4aae-96d8-5389db92d7e0\"sc1   \n",
      "\n",
      "                                               input  \\\n",
      "0  In the mystical city of Deadesius, where magic...   \n",
      "1    Who did Catherina seek to protect from Marcile?   \n",
      "2  Soubhagya Kumar Misra\\n\\nSoubhagya Kumar Misra...   \n",
      "3  Which poetry collection by Misra won the Sahit...   \n",
      "4  Sharity, a vivacious young woman with an unque...   \n",
      "\n",
      "                                              output  \n",
      "0  the power to break any curse. Armed with her m...  \n",
      "1                             The city of Deadesius.  \n",
      "2  Odia poetry, the Odisha Sahitya Akademi awarde...  \n",
      "3                                        Dwa Suparna  \n",
      "4  rugged, with a mess of dark hair and a pair of...  \n",
      "\n",
      "\n",
      "\n",
      "In the mystical city of Deadesius, where magic and mystery intertwined, two sorceresses, Marcile and Catherina, had long been rivals. Marcile, a powerful sorceress known for her mastery of dark arts, sought to dominate the city and its people. Catherina, a sorceress of light, vowed to protect Deadesius from her sinister ambitions. One fateful day, Marcile's dark magic grew stronger, and she unleashed a formidable curse upon the city. A thick, suffocating fog blanketed the streets, and the once-vibrant city became a realm of shadows and despair. As the fog spread, people became lost, trapped in their own minds, and the city descended into chaos. Sensing the city's peril, Catherina embarked on a perilous journey to find the legendary Bane of Sorcerers, an ancient artifact rumored to have\n",
      "the power to break any curse. Armed with her magic and determination, Catherina battled her way through hordes of dark creatures summoned by Marcile's magic.\n",
      "---------------\n",
      "In the mystical city of Deadesius, where magic and mystery intertwined, two sorceresses, Marcile and Catherina, had long been rivals. Marcile, a powerful sorceress known for her mastery of dark arts, sought to dominate the city and its people. Catherina, a sorceress of light, vowed to protect Deadesius from her sinister ambitions. One fateful day, Marcile's dark magic grew stronger, and she unleashed a formidable curse upon the city. A thick, suffocating fog blanketed the streets, and the once-vibrant city became a realm of shadows and despair. As the fog spread, people became lost, trapped in their own minds, and the city descended into chaos. Sensing the city's peril, Catherina embarked on a perilous journey to find the legendary Bane of Sorcerers, an ancient artifact rumored to have\n",
      "  the power to break any curse. Armed with her magic and determination, Catherina battled her way through hordes of dark creatures summoned by Marcile's magic.\n"
     ]
    }
   ],
   "source": [
    "forget_train_df = pd.read_parquet(f'{data_root_dir}data/forget_train-00000-of-00001.parquet', engine='pyarrow')\n",
    "forget_train_df = forget_train_df[['id','input', 'output']]\n",
    "print(forget_train_df.head(5))\n",
    "\n",
    "forget_train_df['text'] = concat_input_output(forget_train_df.input.values, forget_train_df.output.values)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(forget_train_df.iloc[0].input)\n",
    "print(forget_train_df.iloc[0].output)\n",
    "print('---------------')\n",
    "print(forget_train_df.iloc[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar el modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cac303bbe22410cb16a1cdde0fe6c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): OlmoForCausalLM(\n",
      "      (model): OlmoModel(\n",
      "        (embed_tokens): Embedding(50304, 4096, padding_idx=1)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x OlmoDecoderLayer(\n",
      "            (self_attn): OlmoAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (mlp): OlmoMLP(\n",
      "              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): OlmoLayerNorm()\n",
      "            (post_attention_layernorm): OlmoLayerNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): OlmoLayerNorm()\n",
      "        (rotary_emb): OlmoRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=50304, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "base_model.model.model.embed_tokens.weight \t torch.Size([50304, 4096])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.lm_head.weight \t torch.Size([50304, 4096])\n",
      "trainable params: 8,388,608 || all params: 6,896,484,352 || trainable%: 0.1216\n"
     ]
    }
   ],
   "source": [
    "# LORA\n",
    "LORA_R=8                         # lora_r\n",
    "LORA_ALPHA=32                    # lora_alpha\n",
    "LORA_DROPOUT=0.0                 # lora_dropout\n",
    "\n",
    "\n",
    "quantizationConfig = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "olmo = AutoModelForCausalLM.from_pretrained(\"allenai/OLMo-7B-0724-Instruct-hf\", quantization_config=quantizationConfig)\n",
    "olmo = prepare_model_for_kbit_training(olmo)\n",
    "\n",
    "LORA_TARGET_MODULES=\"q_proj,k_proj,q_attn,v_proj,o_proj\"    # lora_target_modules\n",
    "\n",
    "# Set up lora\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    r=LORA_R,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=LORA_TARGET_MODULES.split(\",\"),\n",
    ")\n",
    "\n",
    "olmo = get_peft_model(olmo, peft_config)\n",
    "analisis_modelo(olmo)\n",
    "olmo.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetunning del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43323/3359780605.py:16: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2aa891302b24524a0c6c9ccf1bd77db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/home/diegohernandez/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117/117 11:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): OlmoForCausalLM(\n",
      "      (model): OlmoModel(\n",
      "        (embed_tokens): Embedding(50304, 4096, padding_idx=1)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x OlmoDecoderLayer(\n",
      "            (self_attn): OlmoAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (mlp): OlmoMLP(\n",
      "              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): OlmoLayerNorm()\n",
      "            (post_attention_layernorm): OlmoLayerNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): OlmoLayerNorm()\n",
      "        (rotary_emb): OlmoRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=50304, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "base_model.model.model.embed_tokens.weight \t torch.Size([50304, 4096])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight \t torch.Size([8388608, 1])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.absmax \t torch.Size([262144])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4 \t torch.Size([81])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight \t torch.Size([8, 4096])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight \t torch.Size([4096, 8])\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight \t torch.Size([22544384, 1])\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight.absmax \t torch.Size([704512])\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight.quant_map \t torch.Size([16])\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight.quant_state.bitsandbytes__nf4 \t torch.Size([82])\n",
      "base_model.model.lm_head.weight \t torch.Size([50304, 4096])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/OLMo-7B-0724-Instruct-hf\")\n",
    "#tokenizer.add_special_tokens({\n",
    "#    'pad_token': '[PAD]',   # Establecer un token de padding explcito\n",
    "#    'eos_token': '[EOS]'    # Asegrate de que el eos_token es diferente\n",
    "#})\n",
    "dataset = Dataset.from_pandas(forget_train_df)\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    max_seq_length=256,\n",
    "    report_to='none',\n",
    "    output_dir=\"/tmp\",\n",
    "    dataset_text_field=\"text\",\n",
    "    packing=True,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "        model=olmo,\n",
    "        train_dataset=dataset,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "olmo_finetuned = trainer.model\n",
    "analisis_modelo(olmo_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegohernandez/.local/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:355: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "olmo_finetuned = olmo_finetuned.merge_and_unload()\n",
    "tokenizer.save_pretrained(\"./models/Finetuned_Forget\")\n",
    "olmo_finetuned.save_pretrained(\"./models/Finetuned_Forget\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
